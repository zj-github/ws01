package cn.innohub.crawler.firstlevel.seeds.extract;

import java.net.URL;
import java.util.Date;
import java.util.List;
import java.util.concurrent.CopyOnWriteArrayList;

import cn.innohub.crawler.beans.DetailPageSeed;
import cn.innohub.crawler.beans.FirstLevelSeed;
import cn.innohub.crawler.common.InitParamsConstant;
import cn.innohub.crawler.conf.Configuration;
import cn.innohub.crawler.core.Context;
import cn.innohub.crawler.core.QueueManager;
import cn.innohub.crawler.packageapi.SafeTreeSet;
import cn.innohub.crawler.utils.HttpClientFetcher;
import cn.innohub.crawler.utils.ParseUtil;

/**
 * @ClassName: FisrtLevelSeedWorkShop
 * @Description: 启动抓取算法
 * @author zhangjie
 * @date 2016年1月6日 上午9:20:21
 *
 */
public class FisrtLevelSeedWorkShop {

	/**
	 * while(){ 1、获取nearly url u1。 2、抓取u1
	 * 3、设置u1的下次抓取时间（u1.setNextFetchTime(now+u.interval)） 4、集合排序 5、获取nearly url
	 * u2。 6、算出休眠时间 t1= Set.getFirst.getNextFetchTime() 7、sleep(t1) }
	 * 
	 * @Description: (这里用一句话描述这个方法的作用)
	 * @author zhangjie
	 * @date 2016年1月5日 下午3:42:55
	 * @param args
	 *
	 */
	private SafeTreeSet seeds = Context.getInstance().getFirstLevelSeeds();
	private boolean stop = false;

	public void work() {
		while (!stop) {
			iterator();
		}
	}

	private void iterator() {
		// * 1、弹出nearly url u1。
		// * 2、抓取u1
		// * 3、设置u1的下次抓取时间（u1.setNextFetchTime(now+u.interval)）
		// * 4、集合排序
		// * 5、获取nearly url u2。
		// * 6、算出休眠时间 t1= Set.getFirst.getNextFetchTime()
		// * 7、sleep(t1)
		// 1
		// FirstLevelSeed cur = seeds.pollFirst();
		CopyOnWriteArrayList<FirstLevelSeed> outTimeSeed = getOutTimeSeed();

		// 2、3、
		this.fetchAndExtract(outTimeSeed);

		// 4、
		seeds.addAll(outTimeSeed);// 会从新排序
		// 5、
		FirstLevelSeed first = seeds.first();
		try {
			// 6、休眠时间：下次抓取时间最近的种子的下次抓取时间-到现在的时间
			long sleepInterval = first.getNextFetchTime().getTime() - new Date().getTime();
			// 7、
			Thread.sleep(sleepInterval);
		} catch (InterruptedException e) {
			e.printStackTrace();
		}
	}

	/**
	 * 
	 * @Description: 抓取一级种子，抽取外链，加入详情页种子队列
	 * @author zhangjie
	 * @date 2016年1月6日 上午11:33:56
	 * @param outTimeSeed
	 *
	 */
	public void fetchAndExtract(List<FirstLevelSeed> outTimeSeed) {
		for (FirstLevelSeed seed : outTimeSeed) {
			String htmlContent = HttpClientFetcher.fetchHtmlContent(seed.getUrl());
			List<URL> outLinks = ParseUtil.getOutLinks(seed.getUrl(), htmlContent, seed.getDetailPageReg());// 抽取外链
			List<DetailPageSeed> urlList = new CopyOnWriteArrayList<>();
			for (URL url : outLinks) {// 加入队列
				String clazz = (String) Configuration.getParams(url.getHost());
				urlList.add(new DetailPageSeed(url.toString(), clazz));
			}
			QueueManager.addSeeds(urlList);
			this.setNextFetchTime(seed);// 抓取完成后设置下次抓取时间
		}

	}

	private void setNextFetchTime(FirstLevelSeed cur) {
		long updateFrequency = cur.getUpdateFrequency();
		long interval = Context.getInstance().getLongParams(InitParamsConstant.DEFAULT_INTERVAL);// 默认的抓取间隔
		interval = updateFrequency == 0 ? interval : updateFrequency;
		Date nextFetchTime = new Date(new Date().getTime() + interval);
		cur.setNextFetchTime(nextFetchTime);
	}

	/**
	 * 
	 * @Description:获取 待抓取时间早于当前时间的种子
	 * @author zhangjie
	 * @date 2016年1月6日 上午10:29:14
	 *
	 */
	private CopyOnWriteArrayList<FirstLevelSeed> getOutTimeSeed() {
		return seeds.removeOutTimeSeed(new Date());
	}
}
